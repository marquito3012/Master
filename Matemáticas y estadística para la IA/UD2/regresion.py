# -*- coding: utf-8 -*-
"""Regresion.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dQ4fGN9055ePtRxqBVG4tUYggOfGm6J9

**Caso de uso real de predicción usando algoritmo de regresión lineal.**
"""

import numpy as np #operaciones matemáticas
import pandas as pd #manipulacion de tablas de datos
import matplotlib.pyplot as plt #visualización de datos
import seaborn as sns #visualización de datos
import sklearn #libreria de machine learning-->regresión lineal
import statsmodels.api as sm
import matplotlib.pyplot as plt
from scipy import stats
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline

"""**CARGA DE DATOS**
Se cargan los datos con los que vamos a trabajar
"""

datos_propinas = sns.load_dataset("tips")

"""**Ver aspecto de nuestros datos**"""

print(datos_propinas.head())
datos_propinas.head()

"""**Diccionario de datos**


* **total_bill** indica en dólares el importe total de la cuenta
*  **tip** indica en dólares el importe de la propina
*  **sex** indica el género del cliente que realizó el pago
*  **smoker** indica si la persona que realizó el pago fumaba o no
* **Day** indica el día de la semana
*  **time** indica la comida
*  **size** indica el número de personas

**EXPLORACIÓN DE DATOS**

Siempre que nos enfrentemos a un dataset que no conocemos es útil realizar un análisis previo exploratorio para entender las variables con las que trabajamos. La visualización de datos nos permite comprender de forma ágil las distintas variables. Lo anterior es de importancia, sobre todo, en casos donde no conocemos o no tenemos 100% claros sus significados.

**VARIABLES CATEGÓRICAS**

Comenzamos explorando las variables categóricas
"""

plt.figure(figsize=(6, 4)) #Tamaño de la gráfica
sns.countplot(x='sex', data=datos_propinas, hue='sex', palette=['#FF9999', '#66b2FF'], legend=True) #Construcción de la gráfica
#Adaptamos la información
plt.title("Distribución de género del pagador")
plt.xlabel("Género")
plt.ylabel("Número de pagadores")
plt.show()

plt.figure(figsize=(6, 4)) #Tamaño de la gráfica
sns.countplot(x='sex', data=datos_propinas, palette=['#FF9999', '#66b2FF']) #Construcción de la gráfica

#Adaptamos la información
plt.title("Distribución de género del pagador")
plt.xlabel("Género")
plt.ylabel("Número de pagadores")
plt.show()

plt.figure(figsize=(6, 4)) #Tamaño de la gráfica
sns.countplot(x='smoker', data=datos_propinas, hue='smoker', palette=['#FF9999', '#66b2FF'], legend=True) #Construcción de la gráfica
#Adaptamos la información
plt.title("Distribución de comensales fumadores y no fumadores")
plt.xlabel("Fumador")
plt.ylabel("Cantidad de comensales")
plt.show()

plt.figure(figsize=(6, 4)) #Tamaño de la gráfica
sns.countplot(x='day', data=datos_propinas, hue='day', palette=['#FF9999', '#66b2FF', '#FFCC99', '#99CCFF'], legend=True) #Construcción de la gráfica
#Adaptamos la información
plt.legend(title='Día', bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0) #Pone leyenda fuera del gráfico
plt.title("Distribución día de la semana")
plt.xlabel("Día")
plt.ylabel("Cantidad de comensales")
plt.show()

plt.figure(figsize=(6, 4)) #Tamaño de la gráfica
sns.countplot(x='time', data=datos_propinas, hue='time', palette=['#FFCC99', '#99CCFF'], legend=True) #Construcción de la gráfica
#Adaptamos la información
plt.title("Distribución de momento del día")
plt.xlabel("Horario")
plt.ylabel("Cantidad de comensales")
plt.show()

plt.figure(figsize=(6, 4)) #Tamaño de la gráfica
sns.countplot(x='size', data=datos_propinas, hue='size', palette='Set1', legend=True) #Construcción de la gráfica
#Adaptamos la información
plt.title("Distribución número de comensales por mesa")
plt.xlabel("Número de comensales")
plt.ylabel("Cantidad de facturas")
plt.show()

"""**VARIABLES NÚMERICA**

En la exploración de variables númericas podemos apoyarnos en distintos estadísticos.



"""

def calcula_estadisticos(dataset, variable):
  media=dataset[variable].mean()
  mediana=dataset[variable].median()
  minimo=dataset[variable].min()
  maximo=dataset[variable].max()
  varianza=dataset[variable].var()
  desviacion_estandar=dataset[variable].std()
  resultados={"media":media, "mediana":mediana, "minimo":minimo, "maximo":maximo, "varianza":varianza, "desviacion_estandar":desviacion_estandar}
  return resultados

"""Explorando las dos variables numéricas:"""

resultados_propina=calcula_estadisticos(datos_propinas, "tip")
resultados_propina

resultados_cuenta=calcula_estadisticos(datos_propinas, "total_bill")
resultados_cuenta

# Histograma y curva de densidad
plt.figure(figsize=(8, 5))
sns.histplot(datos_propinas['total_bill'], kde=True, color="#66b2FF", bins=20)
plt.title("Distribución de la factura total")
plt.xlabel("Monto total de la factura")
plt.ylabel("Frecuencia")
plt.show()

# Gráfico de densidad (KDE)
plt.figure(figsize=(8, 5))
sns.kdeplot(datos_propinas['total_bill'], fill=True, color="#FF9999")
plt.title("Curva de densidad de la factura total")
plt.xlabel("Monto total de la factura")
plt.ylabel("Densidad")
plt.show()

"""**VALORES ATÍPICOS EN TOTAL DE LA CUENTA**
La salida que se obtiene muestra las observaciones identificadas como atípicas en la variable ***total_bill***. Interpretación:

**total_bill:** Esta columna muestra el monto total de la factura en cada
observación. Estos valores (48.27, 48.17, 50.81, 48.33) son bastante más altos que el promedio de las facturas en el conjunto de datos, lo que hace que se consideren atípicos en base al criterio de Z-score (valores muy alejados de la media, típicamente más de 3 desviaciones estándar).

**tip:** Esta columna muestra la propina correspondiente a cada factura atípica. Las propinas aquí son también más altas que el promedio en el conjunto de datos, probablemente porque las facturas son elevadas.

**INTERPRETACIÓN DE LOS RESULTADOS**

*   **Facturas Elevadas y Atípicas:** Estas observaciones representan facturas inusualmente altas en el conjunto de datos tips, lo que podría deberse a cenas de grupos grandes o eventos especiales en el restaurante. Si el conjunto de datos contiene principalmente facturas más bajas, estos valores destacan por su magnitud.
*   **Posible Variabilidad Genuina:** Dado que no parecen ser errores obvios (como montos negativos o inconsistencias), estos valores pueden representar variabilidad genuina en los datos. Es común que facturas de cenas grandes o especiales sean más elevadas y correspondan a propinas más altas.



"""

# Identificación de valores atípicos antes de la regresión con Z-score
z_scores = np.abs(stats.zscore(datos_propinas['total_bill']))
atipicos_antes = datos_propinas[z_scores > 3]
print("Atípicos antes de la regresión:\n", atipicos_antes[['total_bill', 'tip']])

# Visualización
plt.figure(figsize=(8, 5))
sns.boxplot(x=datos_propinas['total_bill'], color="#99CCFF")
plt.title("Distribución de la factura total con valores atípicos")
plt.xlabel("Monto total de la factura")
plt.show()

"""**Análisis Valores Atípicos en tip**

*   **Propinas altas debido a facturas altas:** Dado que las facturas para estas observaciones (total_bill) también son inusualmente altas, es posible que la relación entre el monto total y la propina sea proporcional. En otras palabras, una factura más alta podría haber motivado a los comensales a dejar una propina mayor.
*   **Variabilidad genuina:**En el contexto de los datos de propinas, es común ver variaciones en los montos de propinas según el monto total de la factura y el nivel de satisfacción del cliente. Estos valores pueden reflejar una variabilidad genuina dentro del comportamiento de los clientes, especialmente en situaciones donde el servicio fue excepcional y los clientes dejaron una propina generosa.

*   **Potencial Sesgo en la Regresión:** Estos valores atípicos podrían influir en el ajuste de una regresión lineal que prediga tip en función de total_bill. Si el modelo de regresión considera estos valores, la relación entre factura y propina podría verse sesgada, haciendo que el modelo sobrestime las propinas para facturas elevadas.





"""

# Identificación de valores atípicos en la variable 'tip' usando Z-score
z_scores_tip = np.abs(stats.zscore(datos_propinas['tip']))
atipicos_propina = datos_propinas[z_scores_tip > 3]  # Valores con Z-score mayor que 3

# Mostrar los valores atípicos en 'tip'
print("Atípicos en propina antes de la regresión:\n", atipicos_propina[['total_bill', 'tip']])

# Visualización de la distribución de propinas y sus valores atípicos
plt.figure(figsize=(8, 5))
sns.boxplot(x=datos_propinas['tip'], color="#FFCC99")
plt.title("Distribución de propina con valores atípicos")
plt.xlabel("Monto de la propina")
plt.show()

"""**ANÁLISIS DE RELACIÓN ENTRE VARIABLES**
<P> Se puede realizar un análisis sobre cómo se relacionan las variables entre ellas, por ejemplo, si según el día se dejan propinas mayores o no.
"""

plt.figure(figsize=(6, 4)) #Tamaño de la gráfica
sns.barplot(x='day', y='tip', data=datos_propinas, palette='Set1', hue='day', errorbar=None) #Construcción de la gráfica
#Personaliza la gráfica
plt.title("Propina según día de la semana")
plt.xlabel("Día de la semana")
plt.ylabel("Propina media")
plt.show()

"""**CONSTRUCCIÓN DE MODELOS**
<P> Una vez se han comprendido los datos, construimos un modelo para intentar predecir las propinas mediante una regresión líneal.

**REGRESIÓN LÍNEAL SIMPLE**
<P> Este modelo intenta predecir la variable objetivo centrándose en una única variable predirtora. **Intentaremos predecir las propinas basándonos en el número de comensales.**
"""

X=datos_propinas[['size']] #Variable predictora (Número de Comenzales)
y=datos_propinas['tip'] #Variable objetivo (Propina)

"""Dividimos el conjunto de datos en entrenamiento y test."""

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""Ya se puede construir el modelo. Usamos la función de ***scikit-learn*** y entyrenamos con los datos de entrenamiento. Ajuste del modelo."""

from sklearn.linear_model import LinearRegression
regresion_simple = LinearRegression()
regresion_simple.fit(X_train, y_train)

predicciones = regresion_simple.predict(X_test)
X_test.head()
y_pred = regresion_simple.predict(X_test)

predicciones [:5]

"""Como hemos reservado algunos datos podemos comprobar cómo de bien funciona el modelo para realizar predicciones"""

from sklearn.metrics import mean_absolute_error
error_medio = mean_absolute_error(y_test, y_pred)
print("El error medio es de:", error_medio)

"""El resultado El error medio es de: 0.865020209422041 representa el Error Medio Absoluto (MAE), que en este caso es aproximadamente 0.87. Esto significa que, en promedio, las predicciones de propinas realizadas por el modelo se desvían 0.87 unidades del valor real en el conjunto de prueba (y_test). **El modelo predice propinas con un error promedio de alrededor de 0.87, lo cual es aceptable dependiendo del rango de la variable tip.**"""

# Cálculo del rango de la variable 'tip'
rango_tip = datos_propinas['tip'].max() - datos_propinas['tip'].min()
print("Rango de la variable 'tip':", rango_tip)

"""Un MAE de 0.87 en el contexto de un rango de 9 sugiere que el modelo predice las propinas de manera razonablemente precisa basándose en el número de comensales."""

# Visualización de la regresión lineal
plt.figure(figsize=(8, 5))
plt.scatter(X, y, color="blue", label="Datos reales")
plt.plot(X_test, y_pred, color="red", label="Predicción de regresión")
plt.title("Regresión lineal: Propina en función del número de comensales")
plt.xlabel("Número de comensales")
plt.ylabel("Propina")
plt.legend()
plt.show()

"""**INTERPRETACIÓN**
<P>**Pendiente Positiva**
<P>La línea de regresión roja tiene una pendiente positiva, lo que indica una relación directa entre el número de comensales y la propina:

-->**Interpretación:** A medida que aumenta el número de comensales, también aumenta la propina promedio. Esto tiene sentido, ya que grupos más grandes suelen gastar más, lo cual puede resultar en una propina mayor.

**Dispersión de los Datos**
<P>Los puntos azules representan los datos reales de propinas para diferentes números de comensales, y la dispersión alrededor de la línea roja es considerable:

-->**Variabilidad Alta:** Existe mucha variabilidad en las propinas para cada número de comensales. Por ejemplo, para 2 o 3 comensales, las propinas varían de menos de 2 hasta más de 6 unidades, mostrando que el número de comensales no es el único factor que influye en la propina.
<P>-->**Limitación del Modelo:** Esta alta dispersión sugiere que el modelo lineal basado solo en el número de comensales no captura todas las variables que podrían influir en la propina, como el monto total de la cuenta, el día de la semana, o la satisfacción del servicio.

**Ajuste del Modelo**
<P>La línea de regresión proporciona una predicción promedio de propina para cada tamaño de grupo, pero el ajuste no es perfecto debido a la variabilidad mencionada:

-->**Error de Predicción:** Aunque el modelo predice una tendencia positiva (más comensales, mayor propina), no explica todas las observaciones debido a los valores atípicos y la dispersión de los puntos.

**MEJORANDO EL MODELO**
Para mejorar el modelo agregamos las siguientes variables a las predicciones de propina (tip), además del número de comensales (size):

**total_bill:** Esta es la cantidad total de la factura. Es una variable numérica continua.

<p>--> Razonamiento: La cantidad total de la cuenta está probablemente relacionada con la propina, ya que a medida que aumenta el total, es común que también aumente la propina.

**day:**Esta variable indica el día de la semana en que se realizó la transacción (jueves, viernes, sábado, o domingo). Es una variable categórica.
<p>-->Razonamiento: Las propinas podrían variar dependiendo del día de la semana. Por ejemplo, los fines de semana o días de mayor afluencia (viernes y sábado) podrían tener un comportamiento distinto en las propinas.

**time:**Esta variable indica el momento del día en el que se realizó la comida (Lunch para almuerzo y Dinner para cena). Es una variable categórica.
<p>-->Razonamiento: Las propinas podrían variar según el momento del día. Por ejemplo, las cenas suelen tener cuentas más altas y, por ende, podrían llevar a propinas más altas.

**smoker:**Esta variable indica si el cliente es fumador (Yes) o no (No). Es una variable categórica.
<p>-->Razonamiento:Aunque no es una relación obvia, la variable smoker puede ser relevante si se asocia con hábitos de gasto diferentes o una tendencia distinta a dejar propina en ciertos contextos.
"""

# Importación de bibliotecas
import pandas as pd
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import OneHotEncoder
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error
import matplotlib.pyplot as plt

# Cargar los datos desde el conjunto de datos "tips" de seaborn
datos_propinas = sns.load_dataset("tips")

# Separar las características (X) y la variable objetivo (y)
X = datos_propinas[['total_bill', 'size', 'day', 'time', 'smoker']]  # Incluimos más características
y = datos_propinas['tip']

# Codificación de variables categóricas usando OneHotEncoder
preprocesador = ColumnTransformer(
    transformers=[
        ('cat', OneHotEncoder(drop='first'), ['day', 'time', 'smoker'])
    ],
    remainder='passthrough'  # Deja el resto de columnas (numéricas) sin modificar
)

# Creación de un pipeline que primero transforma los datos y luego aplica la regresión lineal
modelo_mejorado = Pipeline(steps=[
    ('preprocesador', preprocesador),
    ('regresion', LinearRegression())
])

# Dividir los datos en conjuntos de entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Entrenar el modelo
modelo_mejorado.fit(X_train, y_train)

# Realizar predicciones en el conjunto de prueba
y_pred = modelo_mejorado.predict(X_test)

# Evaluación del modelo mejorado usando Error Medio Absoluto
error_medio = mean_absolute_error(y_test, y_pred)
print("El error medio es de:", error_medio)

# Visualización de las predicciones frente a los valores reales
plt.figure(figsize=(8, 5))
plt.scatter(y_test, y_pred, color="blue", label="Predicciones vs Reales")
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2, label="Línea Ideal")
plt.xlabel("Valor Real de Propina")
plt.ylabel("Predicción de Propina")
plt.legend()
plt.title("Predicciones del modelo mejorado")
plt.show()

"""**Explicación del Código**
<p>ColumnTransformer y OneHotEncoder:

**ColumnTransformer** permite aplicar transformaciones específicas a ciertas columnas. En este caso, usamos **OneHotEncoder** para convertir las variables categóricas (day, time, smoker) en variables numéricas binarias (0 y 1), ya que los modelos de regresión no pueden procesar variables categóricas directamente.
**drop='first'** en OneHotEncoder elimina una categoría de cada variable categórica para evitar problemas de multicolinealidad.
<p>Pipeline:

Creamos un Pipeline que primero transforma las variables categóricas y luego aplica la regresión lineal. Esto hace que el código sea más limpio y facilita la integración de transformación y modelo.

El modelo mejorado entrega un error de 0.67 que es menor que el del modelo anterior (0.87), significa que este modelo es más preciso y está capturando mejor los factores que afectan la propina. Agregar más variables predictoras permite al modelo entender mejor las variaciones en la propina y realizar predicciones más cercanas a los valores reales.
"""

# Crear un nuevo DataFrame con los datos de entrada
nuevos_datos = pd.DataFrame({
    'total_bill': [500],
    'size': [5],
    'day': ['Sat'],
    'time': ['Dinner'],
    'smoker': ['No']
})

# Hacer la predicción usando el modelo mejorado entrenado
prediccion = modelo_mejorado.predict(nuevos_datos)

print("La propina predicha es de:", prediccion[0])

"""**CONCLUSION**
<p>Hemos realizado dos análisis de regresión para predecir una variable numérica.

Sobre la base de este codigo, hacer modificaciones y experimentar con otros valores.
"""